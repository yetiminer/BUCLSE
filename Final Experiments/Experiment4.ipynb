{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pure tabular learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this allows relative imports in notebook\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from UCLSE.dyna_q.Experiment4 import Experiment,Dyna_QAgentTabular\n",
    "from UCLSE.dyna_q.dyna_q import TabularMemory\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import visdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "name='Experiment4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "vis=visdom.Visdom(port=8097)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_oracle(observation,cutoff=50,ub=6,lb=-2,lamb=0.5):\n",
    "\n",
    "\n",
    "    distance=observation.distance\n",
    "    inventory=observation.inventory\n",
    "    orders_out=observation.orders_out\n",
    "    bid_change=observation.bid_change\n",
    "    bid_ask_spread=observation.bid_ask_spread\n",
    "    time_left=observation.time_left\n",
    "\n",
    "    ans=lamb*bid_change\n",
    "\n",
    "    if inventory==0:   #terminal            \n",
    "            \n",
    "            ans+=-(1-lamb)*distance\n",
    "            ans-=lamb*bid_change\n",
    "\n",
    "    elif inventory>1: #terminal\n",
    "            \n",
    "            ans+=-bid_ask_spread*(inventory-1)\n",
    "            ans+=-(1-lamb)*distance\n",
    "           \n",
    "    else:\n",
    "\n",
    "            if orders_out>0: \n",
    "                ans+=1/250\n",
    "\n",
    "\n",
    "            if time_left==1: #terminal takes account of exit spread\n",
    "               \n",
    "                ans+=-(1-lamb)*distance\n",
    "\n",
    "            if -distance>=ub:\n",
    "                \n",
    "                ans+=-(1-lamb)*distance\n",
    "              \n",
    "\n",
    "            elif -distance<lb:\n",
    "               \n",
    "                ans+=-(1-lamb)*distance\n",
    "               \n",
    "\n",
    "    return ans \n",
    "\n",
    "def done_oracle(observation,cutoff=50,lb=-2,ub=6):\n",
    "\n",
    "    distance=observation.distance\n",
    "    inventory=observation.inventory\n",
    "    orders_out=observation.orders_out\n",
    "    time_left=observation.time_left\n",
    "\n",
    "    if inventory==0:\n",
    "        done=1\n",
    "        why=f'inventory {inventory}=0'\n",
    "    elif time_left>=1:\n",
    "        done=1\n",
    "        why=f'time up {time_left}'\n",
    "    elif inventory>1:\n",
    "        done=1\n",
    "        why=f'inventory {inventory}>1'\n",
    "    elif -distance>=ub:\n",
    "        done=1\n",
    "        why=f'-distance {distance} >ub {ub}'\n",
    "    elif -distance<lb: \n",
    "        done=1\n",
    "        why=f'-distance {distance}<lb {lb}'\n",
    "\n",
    "    else:\n",
    "        done=0 \n",
    "        why=None\n",
    "    return done,why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n"
     ]
    }
   ],
   "source": [
    "trader_pref_kwargs={'qty_min':-5,'qty_max':5,'sigma_pv':1}\n",
    "timer_kwargs={'start':0,'end':5000,'step':1}\n",
    "price_sequence_kwargs={'kappa':0.0002,'mean':100,'sigma':1,'block_length':10}\n",
    "noise_kwargs={'sigma':1}\n",
    "messenger_kwargs={'logging':True}\n",
    "env_kwargs={'trader_arrival_rate':1,'recording':True,#'process_verbose':False,\n",
    "                'bookkeep_verbose':False, 'lob_verbose':False}\n",
    "sigma_n=5\n",
    "\n",
    "def cont_coef():\n",
    "    return np.random.uniform(0.2,0.8)\n",
    "\n",
    "def personal_memory():\n",
    "    return int(np.random.uniform(5,15))\n",
    "\n",
    "trader_kwargs={'ZIP':{'prefix':'ZIP','number':10,'object_name':'WW_Zip',\n",
    "                          'setup_kwargs':\n",
    "                                {'market_make':True,'prior':(100,sigma_n)}},\n",
    "               'HBL':{'prefix':'HBL','number':10,'object_name':'HBL',\n",
    "                          'setup_kwargs':\n",
    "                              {'memory':100,'grace_period':20}},\n",
    "               'CON':{'prefix':'CON','number':10,'object_name':'ContTrader',\n",
    "                      'setup_kwargs':\n",
    "                          {'cont_coeff':cont_coef,'personal_memory':personal_memory,'profit_target':4, 'market_make':True,\n",
    "                          'prior':(100,sigma_n)}},\n",
    "               'NOI':{'prefix':'NOI','number':10,'object_name':'NoiseTrader',\n",
    "                          'setup_kwargs':{'memory':20}}\n",
    "              }\n",
    "\n",
    "lobenv_kwargs={'cutoff':100,'profit_target':10,'loss_limit':-2,'reward_func':reward_oracle,'lamb':0.5}\n",
    "\n",
    "\n",
    "exploration ={\"mode\":'Greedy',\n",
    "        \"type\": \"exponential\",\n",
    "        \"init_epsilon\": 0.8,\n",
    "        \"min_epsilon\": 0.01,\n",
    "        \"decay_steps\": 100000,\n",
    "        \"decay_eps\": 0.99,\n",
    "        \"choice\":'least_bonus'}\n",
    "\n",
    "agent_kwargs={'n_actions':5,'initial_Q':1,'init_epsilon':0.8,'exploration':exploration,\n",
    "             'memory_capacity':1000000,'n_statespace':9,'discount':0.99}\n",
    "\n",
    "\n",
    "\n",
    "experiment=Experiment(trader_pref_kwargs,timer_kwargs,\n",
    "           price_sequence_kwargs,noise_kwargs,\n",
    "           messenger_kwargs,env_kwargs,trader_kwargs,\n",
    "           lobenv_kwargs,agent_kwargs=agent_kwargs,visdom=vis,agent=Dyna_QAgentTabular,name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.new_train_setup(planning_steps=1,planning=True,graph=True,MaxEpisodes=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploration is Greedy\n",
      "Saving best checkpoint at episode 364 with reward 0.09331999999999999\n",
      "Dyna-Q - EXP: 1 | Ep: 381 | timestep: 3 | Ep_r:  0.004 Profit: -1 Avg loss:0.05068000000000002 |  Time to backup 0.0\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 401 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:0.04812000000000001 |  Time to backup 0.0\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 421 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:0.12140000000000001 |  Time to backup 0.01562666893005371\n",
      "Dyna-Q - EXP: 1 | Ep: 441 | timestep: 9 | Ep_r:  0.032 Profit: -1 Avg loss:0.1106 |  Time to backup 0.0\n",
      "Dyna-Q - EXP: 1 | Ep: 461 | timestep: 4 | Ep_r:  1.008 Profit: -1 Avg loss:0.10020000000000001 |  Time to backup 0.0\n",
      "Dyna-Q - EXP: 1 | Ep: 481 | timestep: 12 | Ep_r:  1.016 Profit: 0 Avg loss:0.17788000000000004 |  Time to backup 0.015619039535522461\n",
      "Saving best checkpoint at episode 480 with reward 0.16875999999999997\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 501 | timestep: 10 | Ep_r:  0.024 Profit: -1 Avg loss:0.18256 |  Time to backup 0.0032901763916015625\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 521 | timestep: 1 | Ep_r:  0.25 Profit: 0 Avg loss:0.1574 |  Time to backup 0.0\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Saving best checkpoint at episode 535 with reward 0.17788000000000004\n",
      "Dyna-Q - EXP: 1 | Ep: 541 | timestep: 3 | Ep_r:  0.008 Profit: -1 Avg loss:0.16079999999999994 |  Time to backup 0.0\n",
      "Dyna-Q - EXP: 1 | Ep: 561 | timestep: 8 | Ep_r:  -0.242 Profit: -2 Avg loss:0.25683999999999996 |  Time to backup 0.010238885879516602\n",
      "Dyna-Q - EXP: 1 | Ep: 581 | timestep: 3 | Ep_r:  0.004 Profit: -1 Avg loss:0.20443999999999996 |  Time to backup 0.010216951370239258\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 601 | timestep: 10 | Ep_r:  0.028 Profit: -1 Avg loss:0.11427999999999999 |  Time to backup 0.0\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 621 | timestep: 4 | Ep_r:  1.008 Profit: 0 Avg loss:-0.015559999999999992 |  Time to backup 0.010281801223754883\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 641 | timestep: 11 | Ep_r:  0.028 Profit: -1 Avg loss:-0.07919999999999999 |  Time to backup 0.01562190055847168\n",
      "Dyna-Q - EXP: 1 | Ep: 661 | timestep: 6 | Ep_r:  0.004 Profit: -1 Avg loss:-0.18955999999999995 |  Time to backup 0.01562356948852539\n",
      "Dyna-Q - EXP: 1 | Ep: 681 | timestep: 11 | Ep_r:  0.024 Profit: -1 Avg loss:0.030280000000000022 |  Time to backup 0.015610456466674805\n",
      "Dyna-Q - EXP: 1 | Ep: 701 | timestep: 11 | Ep_r:  0.012 Profit: -1 Avg loss:0.11715999999999997 |  Time to backup 0.015621185302734375\n",
      "Saving best checkpoint at episode 703 with reward 0.18167999999999998\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 721 | timestep: 2 | Ep_r:  0.004 Profit: 39 Avg loss:0.012480000000000012 |  Time to backup 0.015620946884155273\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 741 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:0.03168000000000002 |  Time to backup 0.0\n",
      "Dyna-Q - EXP: 1 | Ep: 761 | timestep: 20 | Ep_r:  0.052000000000000046 Profit: -2 Avg loss:0.08536000000000002 |  Time to backup 0.015622138977050781\n",
      "Dyna-Q - EXP: 1 | Ep: 781 | timestep: 2 | Ep_r:  0.004 Profit: -1 Avg loss:0.14332 |  Time to backup 0.015622854232788086\n",
      "Saving best checkpoint at episode 794 with reward 0.20699999999999996\n",
      "Dyna-Q - EXP: 1 | Ep: 801 | timestep: 7 | Ep_r:  0.016000000000000014 Profit: -1 Avg loss:0.19792000000000004 |  Time to backup 0.015621185302734375\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 821 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:0.15164000000000002 |  Time to backup 0.0\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 841 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:-0.008519999999999986 |  Time to backup 0.015625\n",
      "Dyna-Q - EXP: 1 | Ep: 861 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:-0.020279999999999986 |  Time to backup 0.0\n",
      "Dyna-Q - EXP: 1 | Ep: 881 | timestep: 9 | Ep_r:  0.028 Profit: -2 Avg loss:0.10488000000000001 |  Time to backup 0.015622138977050781\n",
      "Saving best checkpoint at episode 898 with reward 0.2134\n",
      "Dyna-Q - EXP: 1 | Ep: 901 | timestep: 3 | Ep_r:  0.004 Profit: -2 Avg loss:0.25588 |  Time to backup 0.015622377395629883\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 921 | timestep: 4 | Ep_r:  0.008 Profit: -1 Avg loss:0.28264 |  Time to backup 0.0\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 941 | timestep: 8 | Ep_r:  2.024 Profit: 1 Avg loss:0.3128 |  Time to backup 0.015618562698364258\n",
      "Saving best checkpoint at episode 949 with reward 0.21516000000000002\n",
      "Dyna-Q - EXP: 1 | Ep: 961 | timestep: 9 | Ep_r:  0.024 Profit: -1 Avg loss:0.11924000000000001 |  Time to backup 0.0\n",
      "Dyna-Q - EXP: 1 | Ep: 981 | timestep: 5 | Ep_r:  0.016000000000000014 Profit: -3 Avg loss:0.18239999999999998 |  Time to backup 0.015621423721313477\n",
      "Dyna-Q - EXP: 1 | Ep: 1001 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:0.10336000000000002 |  Time to backup 0.015623331069946289\n",
      "Saving checkpoint at episode 1000\n"
     ]
    }
   ],
   "source": [
    "experiment.train(MaxEpisodes=1001,folder='Results/'+experiment.name,start_episode=experiment.episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'Results/Experiment4\\dyna_checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'Results/Experiment4\\dyna_checkpoint.pth.tar' (epoch 1001)\n",
      "keys unused in checkpoint data:  ['episode', 'learn_step_counter', 'setup']\n"
     ]
    }
   ],
   "source": [
    "Experiment.resume(exp=experiment,best=False,folder='Results/'+experiment.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micro_zo50ceu\\OneDrive - University College London\\BUCLSE\\UCLSE\\dyna_q\\Experiment1a.py:554: UserWarning: no eval net for agent, skipping\n",
      "  warnings.warn('no eval net for agent, skipping')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dyna-Q - EXP 1, | Ep: , 1, | timestep:  2 | Ep_r: 0.0|profit:-2 start:237|end:239\n",
      "Dyna-Q - EXP 1, | Ep: , 26, | timestep:  1 | Ep_r: 0.0|profit:-1 start:3176|end:3177\n",
      "r0 0.5\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP 1, | Ep: , 51, | timestep:  2 | Ep_r: 0.0|profit:-1 start:2126|end:2128\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "r0 -0.5\n",
      "Dyna-Q - EXP 1, | Ep: , 76, | timestep:  2 | Ep_r: 0.0|profit:-1 start:938|end:940\n",
      "r0 0.5\n",
      "Dyna-Q - EXP 1, | Ep: , 101, | timestep:  1 | Ep_r: 0.0|profit:-1 start:3785|end:3786\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "r0 1.0\n",
      "Dyna-Q - EXP 1, | Ep: , 126, | timestep:  3 | Ep_r: 0.0|profit:-1 start:2558|end:2561\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "r0 0.5\n",
      "r0 -0.5\n",
      "Dyna-Q - EXP 1, | Ep: , 151, | timestep:  24 | Ep_r: -1.1525061756920736|profit:-3 start:1516|end:1540\n",
      "r0 0.5\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP 1, | Ep: , 176, | timestep:  1 | Ep_r: 0.0|profit:-1 start:592|end:593\n",
      "r0 0.5\n",
      "Dyna-Q - EXP 1, | Ep: , 201, | timestep:  5 | Ep_r: 0.011683580039999999|profit:-2 start:3440|end:3445\n",
      "r0 0.5\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP 1, | Ep: , 226, | timestep:  4 | Ep_r: 0.007801595999999999|profit:-1 start:2129|end:2133\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP 1, | Ep: , 251, | timestep:  2 | Ep_r: -0.995|profit:-2 start:797|end:799\n",
      "r0 -0.5\n",
      "r0 0.5\n",
      "Dyna-Q - EXP 1, | Ep: , 276, | timestep:  1 | Ep_r: 0.0|profit:-1 start:3585|end:3586\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "r0 0.5\n",
      "r0 0.5\n",
      "Dyna-Q - EXP 1, | Ep: , 301, | timestep:  22 | Ep_r: 0.044088707572889366|profit:-1 start:2295|end:2317\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-e6d1351544e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mexperiment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_setup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMaxEpisodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\OneDrive - University College London\\BUCLSE\\UCLSE\\dyna_q\\Experiment1a.py\u001b[0m in \u001b[0;36mtest_setup\u001b[1;34m(self, lobenv_kwargs, MaxEpisodes, agent)\u001b[0m\n\u001b[0;32m    554\u001b[0m                                         \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'no eval net for agent, skipping'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrwd_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 556\u001b[1;33m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMaxEpisodes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    557\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m                 \u001b[1;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mMaxEpisodes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstart_episode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - University College London\\BUCLSE\\UCLSE\\dyna_q\\Experiment1a.py\u001b[0m in \u001b[0;36mtest\u001b[1;34m(self, MaxEpisodes, start_episode, agent)\u001b[0m\n\u001b[0;32m    575\u001b[0m                                         \u001b[1;31m#not double q\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m                                         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 577\u001b[1;33m                                 \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlobenv_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    578\u001b[0m                                 \u001b[0mstart_balance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlobenv_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbalance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m                                 \u001b[0mep_r\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlobenv_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlamb\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mr0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - University College London\\BUCLSE\\UCLSE\\minimal_lobenv.py\u001b[0m in \u001b[0;36mreset\u001b[1;34m(self, wait_period, hard)\u001b[0m\n\u001b[0;32m    294\u001b[0m                         \u001b[1;32mwhile\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m<\u001b[0m\u001b[0mwait_period\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m                                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_period\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimulate_one_period\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mupdating\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                                 \u001b[0mbuffer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - University College London\\BUCLSE\\UCLSE\\wang_wellman_new.py\u001b[0m in \u001b[0;36msimulate_one_period\u001b[1;34m(self, recording, updating)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m                 \u001b[0mlob\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 281\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[0mupdating\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlob\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_traders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    282\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mrecording\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - University College London\\BUCLSE\\UCLSE\\wang_wellman_new.py\u001b[0m in \u001b[0;36mupdate_traders\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    311\u001b[0m                 \u001b[0mlob\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexchange\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpublish_lob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 313\u001b[1;33m                         \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrespond\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrecent_tape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    314\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mlob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - University College London\\BUCLSE\\UCLSE\\WW_traders.py\u001b[0m in \u001b[0;36mrespond\u001b[1;34m(self, time, lob, trade, verbose, tape)\u001b[0m\n\u001b[0;32m    534\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlob_version\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[0mversion\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_lob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 536\u001b[1;33m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_fso\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mversion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    537\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_best\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    538\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - University College London\\BUCLSE\\UCLSE\\WW_traders.py\u001b[0m in \u001b[0;36mupdate_fso\u001b[1;34m(self, input_list, version)\u001b[0m\n\u001b[0;32m    526\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mupdate_fso\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mversion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfso\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mversion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - University College London\\BUCLSE\\UCLSE\\FSO.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, input_list, version)\u001b[0m\n\u001b[0;32m    365\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlast_version\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 367\u001b[1;33m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    368\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mask_q\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m                                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubtract_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - University College London\\BUCLSE\\UCLSE\\FSO.py\u001b[0m in \u001b[0;36madd_all\u001b[1;34m(self, input_list)\u001b[0m\n\u001b[0;32m    404\u001b[0m \t\t\t\t\t\t ]\n\u001b[0;32m    405\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_list\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_to_queue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    407\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0msubtract_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - University College London\\BUCLSE\\UCLSE\\FSO.py\u001b[0m in \u001b[0;36madd_to_queue\u001b[1;34m(self, target_q, input_list)\u001b[0m\n\u001b[0;32m    430\u001b[0m                                 \u001b[0mnew_counts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mq\u001b[0m \u001b[1;31m#gotcha! the dict() method overwrites duplicates in the list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#because each position in queue represents a time period, even periods with no data have positions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                         \u001b[0mnew_counts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mCounter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m                 \u001b[0mtarget_q\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_counts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gym2\\lib\\collections\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    565\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'expected at most 1 arguments, got %d'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 567\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCounter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    568\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "experiment.test_setup(MaxEpisodes=5000,agent=experiment.agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state counter length: 1163, state_action counter length: 1231, total experiences: 6502"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.agent.tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
