{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dyna Q model, CVAE, reward model and terminal model trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this allows relative imports in notebook\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "name='Experiment1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from UCLSE.dyna_q.Experiment1a import Experiment\n",
    "from UCLSE.dyna_q.dyna_q import TabularMemory\n",
    "from UCLSE.dyna_q.benchmarking import BenchmarkAgent, SpoofAgent, DoNothing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import visdom\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "vis=visdom.Visdom(port=8097)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_oracle(observation,cutoff=50,ub=6,lb=-2,lamb=0.5):\n",
    "\n",
    "\n",
    "    distance=observation.distance\n",
    "    inventory=observation.inventory\n",
    "    orders_out=observation.orders_out\n",
    "    bid_change=observation.bid_change\n",
    "    bid_ask_spread=observation.bid_ask_spread\n",
    "    time_left=observation.time_left\n",
    "\n",
    "    ans=lamb*bid_change\n",
    "\n",
    "    if inventory==0:   #terminal            \n",
    "            \n",
    "            ans+=-(1-lamb)*distance\n",
    "            ans-=lamb*bid_change\n",
    "\n",
    "    elif inventory>1: #terminal\n",
    "            \n",
    "            ans+=-bid_ask_spread*(inventory-1)\n",
    "            ans+=-(1-lamb)*distance\n",
    "            ans+=-1 #penalty\n",
    "           \n",
    "    else:\n",
    "\n",
    "            if orders_out>0: \n",
    "                ans+=1/250\n",
    "\n",
    "\n",
    "            if time_left==1: #terminal takes account of exit spread\n",
    "               \n",
    "                ans+=-(1-lamb)*distance\n",
    "\n",
    "            if -distance>=ub:\n",
    "                \n",
    "                ans+=-(1-lamb)*distance\n",
    "              \n",
    "\n",
    "            elif -distance<lb:\n",
    "               \n",
    "                ans+=-(1-lamb)*distance\n",
    "               \n",
    "\n",
    "    return ans \n",
    "\n",
    "def done_oracle(observation,cutoff=50,lb=-2,ub=6):\n",
    "\n",
    "    distance=observation.distance\n",
    "    inventory=observation.inventory\n",
    "    orders_out=observation.orders_out\n",
    "    time_left=observation.time_left\n",
    "\n",
    "    if inventory==0:\n",
    "        done=1\n",
    "        why=f'inventory {inventory}=0'\n",
    "    elif time_left>=1:\n",
    "        done=1\n",
    "        why=f'time up {time_left}'\n",
    "    elif inventory>1:\n",
    "        done=1\n",
    "        why=f'inventory {inventory}>1'\n",
    "    elif -distance>=ub:\n",
    "        done=1\n",
    "        why=f'-distance {distance} >ub {ub}'\n",
    "    elif -distance<lb: \n",
    "        done=1\n",
    "        why=f'-distance {distance}<lb {lb}'\n",
    "\n",
    "    else:\n",
    "        done=0 \n",
    "        why=None\n",
    "    return done,why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trader_pref_kwargs={'qty_min':-5,'qty_max':5,'sigma_pv':1}\n",
    "timer_kwargs={'start':0,'end':6000,'step':1}\n",
    "price_sequence_kwargs={'kappa':0.0002,'mean':100,'sigma':1,'block_length':10}\n",
    "noise_kwargs={'sigma':1}\n",
    "messenger_kwargs={'logging':True}\n",
    "env_kwargs={'trader_arrival_rate':1,'recording':True,#'process_verbose':False,\n",
    "                'bookkeep_verbose':False, 'lob_verbose':False}\n",
    "sigma_n=5\n",
    "\n",
    "def cont_coef():\n",
    "    return np.random.uniform(0.2,0.8)\n",
    "\n",
    "def personal_memory():\n",
    "    return int(np.random.uniform(5,15))\n",
    "\n",
    "trader_kwargs={'ZIP':{'prefix':'ZIP','number':10,'object_name':'WW_Zip',\n",
    "                          'setup_kwargs':\n",
    "                                {'market_make':True,'prior':(100,sigma_n)}},\n",
    "               'HBL':{'prefix':'HBL','number':10,'object_name':'HBL',\n",
    "                          'setup_kwargs':\n",
    "                              {'memory':100,'grace_period':20}},\n",
    "               'CON':{'prefix':'CON','number':10,'object_name':'ContTrader',\n",
    "                      'setup_kwargs':\n",
    "                          {'cont_coeff':cont_coef,'personal_memory':personal_memory,'profit_target':4, 'market_make':True,\n",
    "                          'prior':(100,sigma_n)}},\n",
    "               'NOI':{'prefix':'NOI','number':10,'object_name':'NoiseTrader',\n",
    "                          'setup_kwargs':{'memory':20}}\n",
    "              }\n",
    "\n",
    "lobenv_kwargs={'cutoff':100,'profit_target':10,'loss_limit':-1,'reward_func':reward_oracle,'lamb':0.5}\n",
    "agent_kwargs={'CVAE':True,'Q_H1Size':16,'Q_H2Size':16,\n",
    "                   'doneModel':None,'rewardModel':None,'loss_func':None}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dyna_config={\n",
    "\t\"double_q_model\": False,\n",
    "\t\"batch_size\": 64,\n",
    "\t\"learning_rate\": 5e-3,\n",
    "\t\"exploration\": {\n",
    "\t\t\"type\": \"exponential\",\n",
    "\t\t\"init_epsilon\": 0.8,\n",
    "\t\t\"min_epsilon\": 0.05,\n",
    "\t\t\"decay_steps\": 100000,\n",
    "\t\t\"decay_eps\": 0.99,\n",
    "        \"choice\":'least_bonus'\n",
    "\t},\n",
    "\t\"memory\": {\n",
    "\t\t\"memory_capacity\": 1000000,\n",
    "\t\t\"prioritized\": False,\n",
    "        \"tabular memory\":True,\n",
    "        \n",
    "\t},\n",
    "\t\"discount\": 0.99,\n",
    "\t\"target_update_freq\": 50,\n",
    "\t\"first_update\": 200,\n",
    "\t\"modify_reward\": False,\n",
    "    \"learn\":'Q',\n",
    "    'double_q_model':True,\n",
    "    'model_update_freq':5,\n",
    "    'planning_freq':5,\n",
    "    'model':'CVAE'\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Device in use is  cuda\n",
      "setup tabular memory\n"
     ]
    }
   ],
   "source": [
    "experiment=Experiment(trader_pref_kwargs=trader_pref_kwargs,timer_kwargs=timer_kwargs,\n",
    "           price_sequence_kwargs=price_sequence_kwargs,noise_kwargs=noise_kwargs,\n",
    "           messenger_kwargs=messenger_kwargs,env_kwargs=env_kwargs,trader_kwargs=trader_kwargs,\n",
    "           lobenv_kwargs=lobenv_kwargs,agent_kwargs=agent_kwargs,visdom=vis,dyna_kwargs=dyna_config,name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.new_train_setup(MaxEpisodes=1000,planning_steps=1,lookback=30,thresh=3,planning=True,graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planning is True, double Q model is True, tabular memory is True\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 21 | timestep: 27 | Ep_r:  0.08714251426115849 Profit: -1 Avg loss:-0.3008563378724598\n",
      "Dyna-Q - EXP: 1 | Ep: 41 | timestep: 20 | Ep_r:  -0.9348806723206442 Profit: -2 Avg loss:-0.8665220310235966\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 61 | timestep: 10 | Ep_r:  0.034247169996478206 Profit: -1 Avg loss:-0.19711409818803904\n",
      "Saving best checkpoint at episode 67 with reward 0\n",
      "not strict double Q model\n",
      "making new directory Results/Experiment1\n",
      "Dyna-Q - EXP: 1 | Ep: 81 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:0.11936300736727175\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 101 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:0.0\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 121 | timestep: 4 | Ep_r:  -0.9822088039999999 Profit: -2 Avg loss:-0.015712293466666662\n",
      "Saving best checkpoint at episode 134 with reward 0.030339710782203246\n",
      "not strict double Q model\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 141 | timestep: 4 | Ep_r:  0.488178405 Profit: 0 Avg loss:0.1709255324397956\n",
      "Dyna-Q - EXP: 1 | Ep: 161 | timestep: 23 | Ep_r:  1.9743695813120608 Profit: 1 Avg loss:0.19948320653937532\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 181 | timestep: 1 | Ep_r:  -2.0 Profit: -3 Avg loss:-0.1774626721931293\n",
      "Dyna-Q - EXP: 1 | Ep: 201 | timestep: 7 | Ep_r:  1.0181738608372042 Profit: 0 Avg loss:-0.5500155952334075\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Saving best checkpoint at episode 215 with reward 0.054062359066666676\n",
      "not strict double Q model\n",
      "copying eval net to target net\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 221 | timestep: 17 | Ep_r:  0.058822722646429244 Profit: -1 Avg loss:0.013873474061295589\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 241 | timestep: 57 | Ep_r:  0.19096077654076818 Profit: -1 Avg loss:0.012179484646939768\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 261 | timestep: 4 | Ep_r:  0.011761596 Profit: -1 Avg loss:0.1848826041194821\n",
      "Saving best checkpoint at episode 266 with reward 0.08635428544389129\n",
      "not strict double Q model\n",
      "Dyna-Q - EXP: 1 | Ep: 281 | timestep: 2 | Ep_r:  0.00396 Profit: -1 Avg loss:0.04805531202859982\n",
      "Dyna-Q - EXP: 1 | Ep: 301 | timestep: 2 | Ep_r:  0.9989600000000001 Profit: 0 Avg loss:-0.016746994303611668\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 321 | timestep: 26 | Ep_r:  -1.412017258322062 Profit: -2 Avg loss:0.021054146619641993\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 341 | timestep: 19 | Ep_r:  1.0605325504657652 Profit: 0 Avg loss:-0.35999720893399034\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "copying eval net to target net\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 361 | timestep: 2 | Ep_r:  0.00396 Profit: -4 Avg loss:-0.009337353597624902\n",
      "Dyna-Q - EXP: 1 | Ep: 381 | timestep: 2 | Ep_r:  0.00396 Profit: -1 Avg loss:-0.07138491459568906\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 401 | timestep: 16 | Ep_r:  -2.4445831084379503 Profit: -4 Avg loss:0.025177151509026722\n",
      "Saving best checkpoint at episode 416 with reward 0.18902982410714278\n",
      "not strict double Q model\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 421 | timestep: 6 | Ep_r:  0.019407940239599998 Profit: 58 Avg loss:0.38168130983441145\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 441 | timestep: 22 | Ep_r:  0.0753477641843816 Profit: -3 Avg loss:0.36239844537944876\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 461 | timestep: 8 | Ep_r:  -0.9707400747004999 Profit: -2 Avg loss:0.023561956585264467\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 481 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:0.007011553379267633\n",
      "Dyna-Q - EXP: 1 | Ep: 501 | timestep: 12 | Ep_r:  -1.4585539486864518 Profit: -2 Avg loss:-0.015698234903175633\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 521 | timestep: 2 | Ep_r:  0.00396 Profit: -3 Avg loss:-0.06586811719065307\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 541 | timestep: 16 | Ep_r:  1.0504168915620498 Profit: 44 Avg loss:0.0853010435016419\n",
      "copying eval net to target net\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 561 | timestep: 8 | Ep_r:  0.026902122228831957 Profit: -3 Avg loss:-0.013389408907599003\n",
      "Dyna-Q - EXP: 1 | Ep: 581 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:-0.05224050154259501\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 601 | timestep: 26 | Ep_r:  0.0785542865425378 Profit: -1 Avg loss:0.15042874844563273\n",
      "Saving best checkpoint at episode 603 with reward 0.24621682638241066\n",
      "not strict double Q model\n",
      "Dyna-Q - EXP: 1 | Ep: 621 | timestep: 2 | Ep_r:  0.00396 Profit: -1 Avg loss:0.2996997984960988\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 641 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:0.00898776825904845\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 661 | timestep: 1 | Ep_r:  0.0 Profit: 51 Avg loss:-0.038764664284667835\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 681 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:0.03491538916308028\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 701 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:0.03478338916308029\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 721 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:-0.042781127008064884\n",
      "Dyna-Q - EXP: 1 | Ep: 741 | timestep: 1 | Ep_r:  0.0 Profit: -3 Avg loss:-0.051031127008064885\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 761 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:0.000132\n",
      "Dyna-Q - EXP: 1 | Ep: 781 | timestep: 2 | Ep_r:  0.0 Profit: -1 Avg loss:0.00825\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 801 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:0.0\n",
      "copying eval net to target net\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 821 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:0.033166666666666664\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 841 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:0.041548666666666664\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 861 | timestep: 1 | Ep_r:  0.0 Profit: -3 Avg loss:0.008382\n",
      "Dyna-Q - EXP: 1 | Ep: 881 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:0.049666666666666665\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 901 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:0.033166666666666664\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 921 | timestep: 5 | Ep_r:  0.0 Profit: -1 Avg loss:0.0754711033668848\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 941 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:0.11599999999999998\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Saving best checkpoint at episode 954 with reward 0.2518895058671804\n",
      "not strict double Q model\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 961 | timestep: 29 | Ep_r:  0.9982065223581562 Profit: 0 Avg loss:0.31543901319559586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 981 | timestep: 100 | Ep_r:  0.7486668261738709 Profit: -2 Avg loss:0.23345516701240604\n",
      "Dyna-Q - EXP: 1 | Ep: 1001 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:0.10716869446066296\n",
      "Saving checkpoint at episode 1000\n",
      "not strict double Q model\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 1021 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:0.10879818522677105\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 1041 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:0.1757784499014244\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 1061 | timestep: 2 | Ep_r:  0.0 Profit: -1 Avg loss:-0.13124121080531956\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 1081 | timestep: 3 | Ep_r:  0.0 Profit: -1 Avg loss:-0.11474121080531959\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 1101 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:-0.008575196092857151\n",
      "Dyna-Q - EXP: 1 | Ep: 1121 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:0.0\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 1141 | timestep: 3 | Ep_r:  0.0 Profit: -1 Avg loss:0.00825\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 1161 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:0.04530339480460803\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 1181 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:-0.0333706268\n",
      "Dyna-Q - EXP: 1 | Ep: 1201 | timestep: 1 | Ep_r:  0.0 Profit: -3 Avg loss:-0.1006397145609239\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 1221 | timestep: 2 | Ep_r:  0.0 Profit: -1 Avg loss:-0.04724116511934654\n",
      "Dyna-Q - EXP: 1 | Ep: 1241 | timestep: 1 | Ep_r:  0.2475 Profit: 0 Avg loss:0.10758333333333332\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 1261 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:0.11648546600133333\n",
      "Dyna-Q - EXP: 1 | Ep: 1281 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:0.2692968671222386\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Saving best checkpoint at episode 1294 with reward 0.2712730272793091\n",
      "not strict double Q model\n",
      "Dyna-Q - EXP: 1 | Ep: 1301 | timestep: 1 | Ep_r:  0.2475 Profit: 0 Avg loss:0.07952942647021313\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 1321 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:0.06039755675621431\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 1341 | timestep: 2 | Ep_r:  0.0 Profit: -1 Avg loss:-0.01317646458159984\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 1361 | timestep: 3 | Ep_r:  0.0 Profit: -1 Avg loss:0.0385252632068326\n",
      "Dyna-Q - EXP: 1 | Ep: 1381 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:0.03512742408821431\n",
      "copying eval net to target net\n",
      "Saving best checkpoint at episode 1392 with reward 0.283525759430715\n",
      "not strict double Q model\n",
      "Dyna-Q - EXP: 1 | Ep: 1401 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:0.26575705803610034\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 1421 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:0.4023412928279164\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 1441 | timestep: 2 | Ep_r:  0.0 Profit: -1 Avg loss:0.272622392503265\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Saving best checkpoint at episode 1443 with reward 0.301941041280042\n",
      "not strict double Q model\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 1461 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:0.35457360613659833\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 1481 | timestep: 3 | Ep_r:  0.0 Profit: -1 Avg loss:0.11317637996968936\n",
      "Dyna-Q - EXP: 1 | Ep: 1501 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:0.05470099343635604\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 1521 | timestep: 13 | Ep_r:  0.995 Profit: 0 Avg loss:0.1921024784128579\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 1541 | timestep: 2 | Ep_r:  0.0 Profit: -3 Avg loss:0.30519673395626573\n",
      "Saving best checkpoint at episode 1542 with reward 0.3554557258365983\n",
      "not strict double Q model\n",
      "copying eval net to target net\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 1561 | timestep: 5 | Ep_r:  0.995 Profit: 0 Avg loss:0.502114886544574\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 1581 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:0.23043278863925878\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 1601 | timestep: 1 | Ep_r:  0.0 Profit: -3 Avg loss:0.02047954445593126\n",
      "Dyna-Q - EXP: 1 | Ep: 1621 | timestep: 6 | Ep_r:  0.0 Profit: -1 Avg loss:0.08968032826029496\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 1641 | timestep: 2 | Ep_r:  0.0 Profit: -1 Avg loss:0.00825\n",
      "Saving best checkpoint at episode 1659 with reward 0.371530067289599\n",
      "not strict double Q model\n",
      "Dyna-Q - EXP: 1 | Ep: 1661 | timestep: 9 | Ep_r:  1.0255931010065436 Profit: 0 Avg loss:0.4618804739365206\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 1681 | timestep: 45 | Ep_r:  -1.7963220840611136 Profit: -4 Avg loss:0.27052107074043347\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 1701 | timestep: 3 | Ep_r:  0.0 Profit: -7 Avg loss:0.10928713270158105\n",
      "Saving best checkpoint at episode 1715 with reward 0.42769403723630245\n",
      "not strict double Q model\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 1721 | timestep: 53 | Ep_r:  -0.6131566824690992 Profit: -2 Avg loss:0.4023593066258224\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 1741 | timestep: 37 | Ep_r:  1.1124347127801706 Profit: 0 Avg loss:0.017388998459989213\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 1761 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:0.13222312897757632\n",
      "Dyna-Q - EXP: 1 | Ep: 1781 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:0.23225200163381957\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 1801 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:0.13453670622945696\n",
      "copying eval net to target net\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 1821 | timestep: 6 | Ep_r:  0.02043754023960001 Profit: -1 Avg loss:-0.07302021227801452\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 1841 | timestep: 2 | Ep_r:  0.995 Profit: 0 Avg loss:0.39152192104441436\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 1861 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:0.06939857223890518\n",
      "Dyna-Q - EXP: 1 | Ep: 1881 | timestep: 4 | Ep_r:  0.00396 Profit: -1 Avg loss:0.04834470018526381\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 1901 | timestep: 3 | Ep_r:  0.0 Profit: -1 Avg loss:0.16755905126727452\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 1921 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:0.18916305190292024\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 1941 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:0.03255619349402588\n",
      "Dyna-Q - EXP: 1 | Ep: 1961 | timestep: 3 | Ep_r:  1.99 Profit: 1 Avg loss:0.17313472165669103\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "copying eval net to target net\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best checkpoint at episode 1973 with reward 0.5395458164849399\n",
      "not strict double Q model\n",
      "Dyna-Q - EXP: 1 | Ep: 1981 | timestep: 2 | Ep_r:  0.0 Profit: -1 Avg loss:0.6104592858630503\n",
      "Dyna-Q - EXP: 1 | Ep: 2001 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:0.23941291526280184\n",
      "Saving checkpoint at episode 2000\n",
      "not strict double Q model\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 2021 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:0.3925182873171618\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 2041 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:0.19159700505309926\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 2061 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:-0.0018248028511995758\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 2081 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:-0.019744907420507312\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 2101 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:-0.22393989076156393\n",
      "Dyna-Q - EXP: 1 | Ep: 2121 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:0.10775\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 2141 | timestep: 5 | Ep_r:  0.0 Profit: -1 Avg loss:0.0\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 2161 | timestep: 2 | Ep_r:  0.0 Profit: -1 Avg loss:0.03453739449250906\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 2181 | timestep: 6 | Ep_r:  0.0 Profit: -1 Avg loss:0.13541229719406053\n",
      "Dyna-Q - EXP: 1 | Ep: 2201 | timestep: 1 | Ep_r:  -2.0 Profit: -3 Avg loss:-0.0815785165001318\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 2221 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:0.027601125284488066\n",
      "Dyna-Q - EXP: 1 | Ep: 2241 | timestep: 24 | Ep_r:  1.0204892551765965 Profit: 0 Avg loss:0.13344959038177173\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 2261 | timestep: 14 | Ep_r:  1.0219021222288318 Profit: 0 Avg loss:0.3723928411449035\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 2281 | timestep: 2 | Ep_r:  -2.49604 Profit: -3 Avg loss:0.1579470181345843\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 2301 | timestep: 4 | Ep_r:  0.995 Profit: 0 Avg loss:0.12053240283095618\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 2321 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:0.2798698954858302\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 2341 | timestep: 4 | Ep_r:  0.011761596 Profit: -1 Avg loss:0.18538224531233333\n",
      "copying eval net to target net\n",
      "Saving best checkpoint at episode 2347 with reward 0.5736845279823158\n",
      "not strict double Q model\n",
      "Dyna-Q - EXP: 1 | Ep: 2361 | timestep: 13 | Ep_r:  -2.4550084091995874 Profit: -3 Avg loss:0.6496861166191292\n",
      "Dyna-Q - EXP: 1 | Ep: 2381 | timestep: 21 | Ep_r:  0.07306850719370162 Profit: -1 Avg loss:0.3620602581319779\n",
      "copying eval net to target net\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 2401 | timestep: 11 | Ep_r:  0.0 Profit: -1 Avg loss:0.26076551994777264\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 2421 | timestep: 2 | Ep_r:  0.0 Profit: -1 Avg loss:0.1637751540956635\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 2441 | timestep: 12 | Ep_r:  2.0017615959999997 Profit: 1 Avg loss:0.270416333618589\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 2461 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:0.27096690495990905\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 2481 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:0.000132\n",
      "Dyna-Q - EXP: 1 | Ep: 2501 | timestep: 5 | Ep_r:  1.99396 Profit: 1 Avg loss:0.07471533333333333\n",
      "copying eval net to target net\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 2521 | timestep: 19 | Ep_r:  0.995 Profit: 0 Avg loss:0.4316907198666666\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 2541 | timestep: 3 | Ep_r:  0.0039204 Profit: -1 Avg loss:0.3427917327922644\n",
      "copying eval net to target net\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 2561 | timestep: 22 | Ep_r:  0.0 Profit: -3 Avg loss:0.32714554965047815\n",
      "Dyna-Q - EXP: 1 | Ep: 2581 | timestep: 37 | Ep_r:  -1.4246522358156184 Profit: -5 Avg loss:0.47216945432951535\n",
      "Saving best checkpoint at episode 2589 with reward 0.6670027771869552\n",
      "not strict double Q model\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 2601 | timestep: 16 | Ep_r:  -1.4480233418565154 Profit: -3 Avg loss:0.6283135127930054\n",
      "Dyna-Q - EXP: 1 | Ep: 2621 | timestep: 19 | Ep_r:  -0.953181217090664 Profit: -2 Avg loss:0.16084374049587183\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 2641 | timestep: 25 | Ep_r:  -1.8944275289092587 Profit: -3 Avg loss:0.1082509121333968\n",
      "Dyna-Q - EXP: 1 | Ep: 2661 | timestep: 4 | Ep_r:  1.006761596 Profit: 0 Avg loss:0.3630470299494262\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 2681 | timestep: 2 | Ep_r:  0.9989600000000001 Profit: 0 Avg loss:0.16103327996610103\n",
      "Dyna-Q - EXP: 1 | Ep: 2701 | timestep: 35 | Ep_r:  -3.388996606299863 Profit: -5 Avg loss:0.017582219031735964\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 2721 | timestep: 2 | Ep_r:  0.995 Profit: 0 Avg loss:0.09670459784092042\n",
      "Dyna-Q - EXP: 1 | Ep: 2741 | timestep: 4 | Ep_r:  0.995 Profit: 0 Avg loss:0.3854960606472034\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 2761 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:0.3495666421180859\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 2781 | timestep: 8 | Ep_r:  2.997052122228832 Profit: 2 Avg loss:0.2677131629531771\n",
      "Dyna-Q - EXP: 1 | Ep: 2801 | timestep: 3 | Ep_r:  1.0028804 Profit: 0 Avg loss:0.6361445407461248\n",
      "copying eval net to target net\n",
      "Saving best checkpoint at episode 2805 with reward 0.6846438043383263\n",
      "not strict double Q model\n",
      "Dyna-Q - EXP: 1 | Ep: 2821 | timestep: 4 | Ep_r:  0.003881196 Profit: -1 Avg loss:0.641198671529087\n",
      "Dyna-Q - EXP: 1 | Ep: 2841 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:0.2885847058454616\n",
      "copying eval net to target net\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 2861 | timestep: 26 | Ep_r:  1.082982741677938 Profit: 0 Avg loss:0.4285446368958555\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 2881 | timestep: 7 | Ep_r:  0.023173860837203998 Profit: -1 Avg loss:0.5755178542171542\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 2901 | timestep: 2 | Ep_r:  0.00396 Profit: -1 Avg loss:0.4604700189439072\n",
      "Dyna-Q - EXP: 1 | Ep: 2921 | timestep: 1 | Ep_r:  0.495 Profit: 1 Avg loss:0.1662197775019804\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 2941 | timestep: 3 | Ep_r:  0.0 Profit: -1 Avg loss:0.1296824898638928\n",
      "Dyna-Q - EXP: 1 | Ep: 2961 | timestep: 32 | Ep_r:  -1.3939921343831414 Profit: -4 Avg loss:0.39989712116132725\n",
      "copying eval net to target net\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 2981 | timestep: 2 | Ep_r:  0.0 Profit: -3 Avg loss:0.06262003470588907\n",
      "Dyna-Q - EXP: 1 | Ep: 3001 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:0.03524117481075668\n",
      "Saving checkpoint at episode 3000\n",
      "not strict double Q model\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 3021 | timestep: 1 | Ep_r:  0.0 Profit: -5 Avg loss:0.4431121748002037\n",
      "Dyna-Q - EXP: 1 | Ep: 3041 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:0.29451619892118797\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 3061 | timestep: 1 | Ep_r:  0.0 Profit: -8 Avg loss:0.06724551920133333\n",
      "Dyna-Q - EXP: 1 | Ep: 3081 | timestep: 2 | Ep_r:  0.0 Profit: -3 Avg loss:0.11027890836441362\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 3101 | timestep: 16 | Ep_r:  1.0504168915620498 Profit: 0 Avg loss:0.05746659076348558\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 3121 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:0.19352356878467253\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 3141 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:0.09980595147628571\n",
      "Dyna-Q - EXP: 1 | Ep: 3161 | timestep: 4 | Ep_r:  0.0 Profit: -1 Avg loss:0.06616666666666667\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 3181 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:0.07656256305206834\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 3201 | timestep: 14 | Ep_r:  3.033501674892409 Profit: 2 Avg loss:0.2193002391062974\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 3221 | timestep: 7 | Ep_r:  1.0181738608372042 Profit: 0 Avg loss:0.5674669614151625\n",
      "Saving best checkpoint at episode 3222 with reward 0.7386305515933594\n",
      "not strict double Q model\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 3241 | timestep: 2 | Ep_r:  0.0 Profit: -1 Avg loss:0.8482883480503006\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 3261 | timestep: 8 | Ep_r:  1.0219021222288318 Profit: 0 Avg loss:0.027243394921791626\n",
      "Dyna-Q - EXP: 1 | Ep: 3281 | timestep: 15 | Ep_r:  1.99 Profit: 1 Avg loss:0.1453389333694824\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 3301 | timestep: 2 | Ep_r:  0.0 Profit: -1 Avg loss:0.5040851886593835\n",
      "copying eval net to target net\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 3321 | timestep: 62 | Ep_r:  3.2679127446487364 Profit: 2 Avg loss:0.18975013729552756\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 3341 | timestep: 40 | Ep_r:  2.118411296572128 Profit: 1 Avg loss:0.1850203679290795\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 3361 | timestep: 26 | Ep_r:  -2.662017258322062 Profit: -1 Avg loss:0.5050160865570957\n",
      "Dyna-Q - EXP: 1 | Ep: 3381 | timestep: 2 | Ep_r:  0.0 Profit: -1 Avg loss:0.3813257007221657\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 3401 | timestep: 27 | Ep_r:  1.0860629142611584 Profit: 0 Avg loss:0.4732183022869924\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 3421 | timestep: 2 | Ep_r:  0.0 Profit: -1 Avg loss:0.42714639436401886\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 3441 | timestep: 2 | Ep_r:  0.0 Profit: -1 Avg loss:0.606584381571427\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 3461 | timestep: 2 | Ep_r:  1.99396 Profit: 1 Avg loss:0.5851113881963176\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 3481 | timestep: 3 | Ep_r:  0.0 Profit: -1 Avg loss:-0.022168257877314527\n",
      "Dyna-Q - EXP: 1 | Ep: 3501 | timestep: 7 | Ep_r:  1.000442960837204 Profit: 0 Avg loss:0.5291844579852772\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "copying eval net to target net\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 3521 | timestep: 2 | Ep_r:  0.9989600000000001 Profit: 0 Avg loss:0.39695361461079737\n",
      "Dyna-Q - EXP: 1 | Ep: 3541 | timestep: 6 | Ep_r:  0.995 Profit: 0 Avg loss:0.5951147496617228\n",
      "copying eval net to target net\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 3561 | timestep: 12 | Ep_r:  1.0314960513135483 Profit: -2 Avg loss:0.30722134297654596\n",
      "Dyna-Q - EXP: 1 | Ep: 3581 | timestep: 4 | Ep_r:  0.011761596 Profit: -1 Avg loss:0.23955951204625356\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 3601 | timestep: 25 | Ep_r:  0.0809114562403413 Profit: -1 Avg loss:0.33254034490201917\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 3621 | timestep: 23 | Ep_r:  1.0735542865425378 Profit: 0 Avg loss:0.47400096842660333\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 3641 | timestep: 16 | Ep_r:  -1.4445831084379503 Profit: -5 Avg loss:0.04662069224421244\n",
      "Dyna-Q - EXP: 1 | Ep: 3661 | timestep: 3 | Ep_r:  0.995 Profit: -2 Avg loss:-0.05049647979816059\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 3681 | timestep: 2 | Ep_r:  0.00396 Profit: -1 Avg loss:0.24017373196991204\n",
      "Dyna-Q - EXP: 1 | Ep: 3701 | timestep: 48 | Ep_r:  1.1407458885772845 Profit: 0 Avg loss:0.15562013584204226\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 3721 | timestep: 2 | Ep_r:  0.0 Profit: -1 Avg loss:0.19751121811300365\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 3741 | timestep: 7 | Ep_r:  0.995 Profit: 0 Avg loss:0.20677960498427905\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 3761 | timestep: 34 | Ep_r:  2.0983037258400072 Profit: 1 Avg loss:0.12213642234910808\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 3781 | timestep: 31 | Ep_r:  0.09987212978008479 Profit: -1 Avg loss:0.35210734871865285\n",
      "Dyna-Q - EXP: 1 | Ep: 3801 | timestep: 2 | Ep_r:  0.00396 Profit: -1 Avg loss:0.09975541860676035\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 3821 | timestep: 2 | Ep_r:  0.00396 Profit: -1 Avg loss:0.1920257516774863\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 3841 | timestep: 2 | Ep_r:  0.00396 Profit: -1 Avg loss:0.04344220666666666\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 3861 | timestep: 9 | Ep_r:  0.015299640169339638 Profit: -1 Avg loss:-0.021864679726355345\n",
      "Dyna-Q - EXP: 1 | Ep: 3881 | timestep: 16 | Ep_r:  1.0504168915620498 Profit: 0 Avg loss:0.3060761921175836\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "copying eval net to target net\n",
      "Saving best checkpoint at episode 3897 with reward 0.74010179935742\n",
      "not strict double Q model\n",
      "Dyna-Q - EXP: 1 | Ep: 3901 | timestep: 100 | Ep_r:  0.24433124426553252 Profit: -1 Avg loss:0.8871872958081336\n",
      "Dyna-Q - EXP: 1 | Ep: 3921 | timestep: 24 | Ep_r:  1.97353588549894 Profit: 1 Avg loss:0.8618227131019052\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 3941 | timestep: 50 | Ep_r:  1.11982410913287 Profit: 0 Avg loss:1.155636401820726\n",
      "Saving best checkpoint at episode 3948 with reward 0.7882519444817824\n",
      "not strict double Q model\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 3961 | timestep: 4 | Ep_r:  0.011761596 Profit: -1 Avg loss:0.2991504154887298\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 3981 | timestep: 1 | Ep_r:  0.0 Profit: -1 Avg loss:-0.05935584355367304\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 4001 | timestep: 12 | Ep_r:  0.037486051313548284 Profit: -3 Avg loss:0.2742020487102569\n",
      "Saving checkpoint at episode 4000\n",
      "not strict double Q model\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 4021 | timestep: 13 | Ep_r:  2.030041590800413 Profit: 1 Avg loss:0.42314724411185434\n",
      "Dyna-Q - EXP: 1 | Ep: 4041 | timestep: 13 | Ep_r:  0.995 Profit: 0 Avg loss:0.28753283261703966\n",
      "copying eval net to target net\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 4061 | timestep: 11 | Ep_r:  0.03786469829651342 Profit: -1 Avg loss:0.28694400164120587\n",
      "Dyna-Q - EXP: 1 | Ep: 4081 | timestep: 8 | Ep_r:  0.02294212222883196 Profit: -3 Avg loss:-0.014065472111479873\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 4101 | timestep: 4 | Ep_r:  2.0017615959999997 Profit: 1 Avg loss:0.106439877971429\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 4121 | timestep: 2 | Ep_r:  0.00396 Profit: -1 Avg loss:0.24181802778121353\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 4141 | timestep: 22 | Ep_r:  -1.4413441969650653 Profit: -3 Avg loss:0.0932445478464845\n",
      "Dyna-Q - EXP: 1 | Ep: 4161 | timestep: 6 | Ep_r:  0.25097401739024994 Profit: 0 Avg loss:-0.23004390820929022\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 4181 | timestep: 4 | Ep_r:  0.011761596 Profit: -1 Avg loss:-0.17138234138861858\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 4201 | timestep: 18 | Ep_r:  -2.437805504580035 Profit: -5 Avg loss:0.10481929287379098\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 4221 | timestep: 49 | Ep_r:  -1.0037223528786074 Profit: -3 Avg loss:0.29760197989799014\n",
      "Dyna-Q - EXP: 1 | Ep: 4241 | timestep: 11 | Ep_r:  0.03786469829651342 Profit: -3 Avg loss:0.2693594748343964\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 4261 | timestep: 39 | Ep_r:  -1.3742916196241133 Profit: -1 Avg loss:0.42955463135836475\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 4281 | timestep: 10 | Ep_r:  0.034247169996478206 Profit: -1 Avg loss:0.062136957599739376\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 4301 | timestep: 29 | Ep_r:  0.980546940507133 Profit: 0 Avg loss:0.17179324651815658\n",
      "copying eval net to target net\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 4321 | timestep: 47 | Ep_r:  -1.8534101579564801 Profit: 25 Avg loss:-0.006578062759493797\n",
      "Dyna-Q - EXP: 1 | Ep: 4341 | timestep: 36 | Ep_r:  -1.3825652872198295 Profit: -2 Avg loss:-0.20229996701696135\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 4361 | timestep: 9 | Ep_r:  0.030593101006543638 Profit: -1 Avg loss:0.24249572903112798\n",
      "Dyna-Q - EXP: 1 | Ep: 4381 | timestep: 15 | Ep_r:  -0.8983426702184794 Profit: -2 Avg loss:0.09444204910808975\n",
      "copying eval net to target net\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 4401 | timestep: 7 | Ep_r:  0.023173860837203998 Profit: -1 Avg loss:-0.04417730088220555\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 4421 | timestep: 17 | Ep_r:  1.0538227226464292 Profit: 0 Avg loss:0.31604624216472493\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 4441 | timestep: 39 | Ep_r:  2.11259709493829 Profit: 1 Avg loss:0.3915537975036851\n",
      "Dyna-Q - EXP: 1 | Ep: 4461 | timestep: 100 | Ep_r:  0.4793903346014454 Profit: -1 Avg loss:0.5564497043641062\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 4481 | timestep: 29 | Ep_r:  -1.2160758141497394 Profit: -6 Avg loss:0.2913974280079477\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 4501 | timestep: 71 | Ep_r:  1.0968055304759283 Profit: 0 Avg loss:0.6380605268471865\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "copying eval net to target net\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 4521 | timestep: 38 | Ep_r:  1.9768434282949827 Profit: 1 Avg loss:0.7902006945965011\n",
      "Dyna-Q - EXP: 1 | Ep: 4541 | timestep: 32 | Ep_r:  3.0620405395703534 Profit: 2 Avg loss:0.2822094212434789\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 4561 | timestep: 25 | Ep_r:  -2.8476013154372763 Profit: -3 Avg loss:0.35816730927418367\n",
      "Dyna-Q - EXP: 1 | Ep: 4581 | timestep: 71 | Ep_r:  2.077381253851816 Profit: 1 Avg loss:0.07924012279571167\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 4601 | timestep: 26 | Ep_r:  1.0272151775360023 Profit: 0 Avg loss:0.596535771602739\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 4621 | timestep: 17 | Ep_r:  -1.9411772773535707 Profit: -3 Avg loss:0.6577810363288905\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 4641 | timestep: 37 | Ep_r:  -0.843702411171382 Profit: -2 Avg loss:0.9465097566852317\n",
      "Dyna-Q - EXP: 1 | Ep: 4661 | timestep: 23 | Ep_r:  3.039843786542538 Profit: 2 Avg loss:0.7897829592835255\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 4681 | timestep: 66 | Ep_r:  1.9887484861631366 Profit: -3 Avg loss:0.9125597099551658\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 4701 | timestep: 74 | Ep_r:  1.348122428766597 Profit: 0 Avg loss:0.8371176162663498\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 4721 | timestep: 93 | Ep_r:  2.045662982533572 Profit: 1 Avg loss:0.5555059331649819\n",
      "Dyna-Q - EXP: 1 | Ep: 4741 | timestep: 28 | Ep_r:  2.04541689156205 Profit: 1 Avg loss:0.6554408829164976\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 4761 | timestep: 9 | Ep_r:  -1.9694068989934563 Profit: -3 Avg loss:0.2078826442420997\n",
      "Dyna-Q - EXP: 1 | Ep: 4781 | timestep: 3 | Ep_r:  0.0078804 Profit: -1 Avg loss:-0.1418255840824029\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 4801 | timestep: 3 | Ep_r:  1.0028804 Profit: 0 Avg loss:0.030820880979227104\n",
      "copying eval net to target net\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "sequence made\n",
      "adding exchange to RL trader  RL\n",
      "adding exchange to RL trader  RL\n",
      "Dyna-Q - EXP: 1 | Ep: 4821 | timestep: 17 | Ep_r:  1.0449127226464292 Profit: 0 Avg loss:0.08205074819670435\n",
      "Dyna-Q - EXP: 1 | Ep: 4841 | timestep: 46 | Ep_r:  2.12799585854893 Profit: 1 Avg loss:0.17371755304106754\n",
      "copying eval net to target net\n",
      "Dyna-Q - EXP: 1 | Ep: 4861 | timestep: 19 | Ep_r:  -4.918607838574235 Profit: -4 Avg loss:0.5013609071763315\n",
      "Dyna-Q - EXP: 1 | Ep: 4881 | timestep: 20 | Ep_r:  -2.2266860406395845 Profit: -3 Avg loss:0.8371013116789865\n"
     ]
    }
   ],
   "source": [
    "experiment.train(MaxEpisodes=10001,start_episode=experiment.episode,folder='Results/'+experiment.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
